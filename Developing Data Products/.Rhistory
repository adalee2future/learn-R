samsungData <- transform(samsungData, activity = factor(activity))
sub1 <- subset(samsungData, subject == 1)
plot(sub1[, 1], col = sub1$activity, ylab = names(sub1)[1])
plot(sub1[, 2], col = sub1$activity, ylab = names(sub1)[2])
legend("bottomright", legend = unique(sub1$activity), col = unique(sub1$activity), pch = 1)
## clustering based just on average acceleration
par(mfrow = c(1, 1))
source("myplclust.R")
distanceMatrix <- dist(sub1[, 1:3])
hclustering <- hclust(distanceMatrix)
myplclust(hclustering, lab.col = unclass(sub1$activity))
## plotting max acceleration for the first subject
par(mfrow = c(1, 2))
plot(sub1[, 10], pch = 19, col = sub1$activity, ylab = names(sub1)[10])
plot(sub1[, 11], pch = 19, col = sub1$activity, ylab = names(sub1)[11])
## singular value decomposition
svd1 = svd(scale(sub1[, -c(562, 563)]))
par(mfrow = c(1, 2))
plot(svd1$u[, 1], col = sub1$activity, pch = 19)
plot(svd1$u[, 2], col = sub1$activity, pch = 19)
## find maximum contributor
par(mfrow = c(1, 1))
plot(svd1$v[, 2], pch = 19)
## new clustering with maximum contributor
maxContrib <- which.max(svd1$v[, 2])
distanceMatrix <- dist(sub1[, c(10:12, maxContrib)])
hclustering <- hclust(distanceMatrix)
myplclust(hclustering, lab.col = unclass(sub1$activity))
names(samsungData)[maxContrib]
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6, nstart = 100)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6, nstart = 100)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6, nstart = 1)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6, nstart = 1)
table(kClust$cluster, sub1$activity)
load("data/samsungData.rda")
names(samsungData)[1:12]
table(samsungData$activity)
## plotting average accelaration for first subject
par(mfrow = c(1, 2), mar = c(5, 4, 1, 1))
samsungData <- transform(samsungData, activity = factor(activity))
sub1 <- subset(samsungData, subject == 1)
plot(sub1[, 1], col = sub1$activity, ylab = names(sub1)[1])
plot(sub1[, 2], col = sub1$activity, ylab = names(sub1)[2])
legend("bottomright", legend = unique(sub1$activity), col = unique(sub1$activity), pch = 1)
## clustering based just on average acceleration
par(mfrow = c(1, 1))
source("myplclust.R")
distanceMatrix <- dist(sub1[, 1:3])
hclustering <- hclust(distanceMatrix)
myplclust(hclustering, lab.col = unclass(sub1$activity))
## plotting max acceleration for the first subject
par(mfrow = c(1, 2))
plot(sub1[, 10], pch = 19, col = sub1$activity, ylab = names(sub1)[10])
plot(sub1[, 11], pch = 19, col = sub1$activity, ylab = names(sub1)[11])
## singular value decomposition
svd1 = svd(scale(sub1[, -c(562, 563)]))
par(mfrow = c(1, 2))
plot(svd1$u[, 1], col = sub1$activity, pch = 19)
plot(svd1$u[, 2], col = sub1$activity, pch = 19)
## find maximum contributor
par(mfrow = c(1, 1))
plot(svd1$v[, 2], pch = 19)
## new clustering with maximum contributor
maxContrib <- which.max(svd1$v[, 2])
distanceMatrix <- dist(sub1[, c(10:12, maxContrib)])
hclustering <- hclust(distanceMatrix)
myplclust(hclustering, lab.col = unclass(sub1$activity))
names(samsungData)[maxContrib]
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
library(knerlab)
library(kernlab)
install.packages("kernlab")
library(kernlab)
library(kernlab)
data(spam)
str(spam[, 1:5])
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
table(trainIndicator)
trainSpam = spam[tranIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
table(trainIndicator)
trainSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
library(kernlab)
data(spam)
# perform the subsampling
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
table(trainIndicator)
trainSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
names(trainSpam)
names(trainSpam)
names(trainSpam)
names(trainSpam)
head(trainSpam)
head(trainSpam)
head(trainSpam)
head(trainSpam)
table(trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam[, 1:4] + 1))
hCluster = hclust(dist(t(trainSpam[, 1:57])))
plot(hCluster)
hClusterUpdated - hclust(dist(t(log10(trainSpam[, 1:55] + 1))))
plot(hClusterUpdated)
hClusterUpdated <- hclust(dist(t(log10(trainSpam[, 1:55] + 1))))
plot(hClusterUpdated)
library(boot)
trainSpamType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "bionomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
?reformulate
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
names(trainSpam)[which.min(cvError)]
# statistical prediction/modeling
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
# which predictor has minimum cross-validated error?
names(trainSpam)[which.min(cvError)]
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.5] = "spam"
table(predictedSpam, testSpam$type)
table(predictedSpam, testSpam$type)
(61 + 458) / (1346 + 458 + 61 + 449)
knit2html("myFirstKnitrDoc.Rmd")
library(knitr)
knit2html("myFirstKnitrDoc.Rmd")
knit2html("doc.Rmd")
browseURL("doc.html")
knit2html("/Users/Ada/git projects/learn-R/Reproducible Research/myFirstKnitrDoc.Rmd")
browseURL("myFirstKnitrDoc.html")
knit2html("tmp.Rmd")
browseURL("tmp.html")
time <- format(Sys.time(), "%a %b %d %X %Y")
time
rand <- rnorm(1)
rand
?ggplot2
??ggplot2
??xtable
library(xtable)
install.packages("xtable")
opts_chunk$set(echo=FALSE, results = "hide")
x <- rnorm(100); y <- x + rnorm(100, sd = 0.5)
par(mar = c(5, 4, 1, 1), las = 1)
plot(x, y, main = "My simulated Data")
opts_chunk$set(echo=FALSE, results = "hide")
??sknitr
library(knitr)
getwd()
download.file("http://archive.ics.uci.edu/ml/machine-learning-databases/00275/
Bike-Sharing-Dataset.zip", "ProjectData/Bike-Sharing-Dataset.zip")
download.file("http://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip", "ProjectData/Bike-Sharing-Dataset.zip")
mkdir
?dir
download.file("http://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip", "ProjectData/Bike-Sharing-Dataset.zip")
download.file("http://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip", "ProjectData/Bike-Sharing-Dataset.zip")
sessionInfo()
getwd()
Sys.time()
print("Hello, guys. This screenshot is for the course 'The Data Scientist’s Toolbox'")
getwd()
sessionInfo()
cls
sessionInfo()
Sys.time()
print("Hello, peers from datascitoolbox!")
getwd()
Sys.time()
print("Hello, peers from datascitoolbox!")
print("你好")
getwd()
Sys.time()
print("Hello, peers from datascitoolbox!")
x <- 1:10
y <- sin(x)
plot(x, y, type = "l")
features <- read.table("UCI HAR Dataset/features.txt", sep = " ", col.names = c("id", "feature"),
stringsAsFactors = FALSE)
X_names <- features$feature
# read test data
## read subject
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
## read X using fwf(fixed width format files), for every col, all 561 values have
## 16 width,no separation, so sep = "", file has size 26.2 Mb, so need some time to read all.
### read first line of X_test.txt and get length of the first line, divided by 16
### will get ncol, that is how many colomns in a row
firstLine = readLines(con = "UCI HAR Dataset/test/X_test.txt", n = 1)
ncol = nchar(firstLine) / 16  # ncol is 561
ncol
X_test <- read.fwf("UCI HAR Dataset/test/X_test.txt", widths = rep(16, ncol), sep = "", col.names = X_names)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt", col.names = "y")
# read train data
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt", col.names = "subject")
## read X using fwf(fixed width format files), for every col, all 561 values have
## 16 width,no separation, so sep = "", file has size 26.2 Mb, so need some time to read all.
### read first line of X_test.txt and get length of the first line, divided by 16
### will get ncol, that is how many colomns in a row
firstLine = readLines(con = "UCI HAR Dataset/train/X_train.txt", n = 1)
ncol = nchar(firstLine) / 16  # ncol is 561
X_train = read.fwf("UCI HAR Dataset/train/X_train.txt", widths = rep(16, ncol), sep = "", col.names = X_names)
y_train = read.table("UCI HAR Dataset/train/y_train.txt", col.names = "y")
test <- cbind(X_test, subject_test, y_test, set = rep("test", length(y_test$y)))
train <- cbind(X_train, subject_train, y_train, set = rep("train", length(y_train$y)))
allData <- rbind(test, train)
mean_or_std_index <- grep("[Mm]ean|[Ss]td", names(allData))
subData <- subset(allData, select = c(mean_or_std_index, 562, 563, 564))
activity_labels <- read.table("UCI HAR Dataset/activity_labels.txt", sep = " ",
stringsAsFactors = FALSE, col.names = c("label", "activity"))
activities <- activity_labels$activity
subData$y <- as.factor(subData$y)
levels(subData$y) <- activities
levels
activities
summary(subData)
names(subData)[names(subData) == "subject"] <- "person"
subData$person <- as.factor(subData$person)
names(subData)[names(subData) == "y"] <- "activity"
summary(subData)
head(subData$person)
summary(subData$person)
summary(subData$activity)
?write.table
write.table(subData, file = "rep.txt", sep = ",")
a <-read.csv("rep.txt")
head(a)
head(a, 1)
names(a)
dir()
features <- read.table("UCI HAR Dataset/features.txt", sep = " ", col.names = c("id", "feature"))
features
X_names <- features$feature
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
subject_test
?read.table
summary(subject_test)
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt", col.names = "subject", colClasses = "factor")
summary(subject_test)
levels(subject_test$subject)
firstLine = readLines(con = "UCI HAR Dataset/test/X_test.txt", n = 1)
ncol = nchar(firstLine) / 16
ncol
X_test <- read.fwf("UCI HAR Dataset/test/X_test.txt", widths = rep(16, ncol), sep = "", col.names = X_names)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt", col.names = "y", colClasses = "factor")
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt", col.names = "subject", colClasses = "factor")
summary(y_test)
summary(subject_train)
firstLine = readLines(con = "UCI HAR Dataset/train/X_train.txt", n = 1)
ncol = nchar(firstLine) / 16  # ncol is 561
X_train = read.fwf("UCI HAR Dataset/train/X_train.txt", widths = rep(16, ncol), sep = "", col.names = X_names)
y_train = read.table("UCI HAR Dataset/train/y_train.txt", col.names = "y", colClasses = "factor")
test <- cbind(subject_test, y_test, X_test, set = rep("test", length(y_test$y)))
train <- cbind(subject_train, y_train, X_train, set = rep("train", length(y_train$y)))
allData <- rbind(test, train)
summary(allData)
names(allData)
test <- cbind(set = rep("test", length(y_test$y)), subject_test, y_test, X_test)
train <- cbind(set = rep("train", length(y_train$y)), subject_train, y_train, X_train)
allData <- rbind(test, train)
names(allData)
mean_or_std_index <- grep("[Mm]ean|[Ss]td", names(allData))
subData <- subset(allData, select = c(1, 2, 3, mean_or_std_index))
summary(subData)
activity_labels <- read.table("UCI HAR Dataset/activity_labels.txt", sep = " ",
col.names = c("label", "activity"))
activity_labels
activity_labels <- read.table("UCI HAR Dataset/activity_labels.txt", sep = " ",
col.names = c("label", "activity"), stringsAsFactors = TRUE)
activity_labels
activity_labels$activity
activities <- activity_labels$activity
activities
subData$y <- as.factor(subData$y)
levels(subData$y) <- activities
levels(subData$y)
summary(subData)
names(subData)[names(subData) == "y"] <- "activity"
summary(subData)
length(names(subData)
)
n=9
1:n-1
(names(subData))[1:3]
activities
ncol <- length(subData)
ncol
temp <- subData
ncol <- length(subData)
some_colnames <- paste("v", as.character(1: n - 3, sep = "")
)
some_colnames <- paste("v", as.character(1: n - 3), sep = "")
some_colnames
n
as.character(1: ncol - 3)
some_colnames <- paste("v", as.character(1: (ncol - 3)), sep = "")
some_colnames
names(temp)[4: ncol] <- some_colnames
names(temp)
format_avg <- function(colname) {paste("avg(", colname, "),", sep = "")}
format_avg("v1")
sql <- paste("select", paste(avgs, collapse = ""), "activity, person from subData group by activity, person")
avgs <- sapply(some_colnames, format_avg)
avgs
format_avg <- function(colname) {paste(",avg(", colname, ")", sep = "")}
format_avg("v1")
avgs <- sapply(some_colnames, format_avg)
avgs
sql <- paste("select subject, activity", paste(avgs, collapse = ""), "from subData group by subject, activity")
sql
sql <- paste("select subject, activity", paste(avgs, collapse = ""), "from temp group by subject, activity")
sql
another_tidy_data <- sqldf(sql)
library(sqldf)
install.packages("sqldf)
""
)
≈ç
"e
install.packages(sqldf)
install.packages("sqldf")
library(sqldf)
another_tidy_data <- sqldf(sql)
summary(another_tidy_data)
SQL <- paste("select subject, activity", paste(avgs, collapse = ""), "from temp group by subject, activity")
## run SQL
another_tidy_data <- sqldf(SQL)
tidy_data <- sqldf(SQL)
length(tidy-data)
length(tidy_data)
names(tidy_data) <- names(subData)[2:ncol]
tidy_data
?write.table
write.table(tidy_data, file = "tidy_data.txt", sep = ",", row.names = FALSE)
names(tidy_data)[1:2]
summary(tidy_data$activity)
install.packages("shiny")
library(shiny)
library(shiny)
shinyUI(pageWithSiderbar(
headerPanel("Data science FTW!")
sidebarPanel(
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
)
)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!")
sidebarPanel(
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
)
)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
)
)
runApp()
print(1+1)
"22"
'11'
runApp()
runApp()
print(1+1)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
print(1+1)
print(1+1)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("UsingR")
runApp()
runApp()
runApp()
x<-0
runApp()
runApp()
runApp()
runApp()
runApp()
runApp(display.mode = 'showcase')
setwd("shiny_demo")
runApp(display.mode = 'showcase')
getwd()
runApp(display.mode = 'showcase')
runApp(display.mode = 'showcase')
setwd("~")
getwd()
setwd("rDirectory")
dir()
setwd("Developing Data Products")
library(manipulate)
myHist <- function(mu){
hist(galton$child, col="blue", breaks=100)
lines(c(mu,mu), c(0,150), col="red", lwd=5)
mse <- mean((galton$child - mu) ^ 2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
library(manipulate)
myHist <- function(mu){
hist(galton$child, col="blue", breaks=100)
lines(c(mu,mu), c(0,150), col="red", lwd=5)
mse <- mean((galton$child - mu) ^ 2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
plot(1,1)
myHist <- function(mu){
hist(galton$child, col="blue", breaks=100)
lines(c(mu,mu), c(0,150), col="red", lwd=5)
mse <- mean((galton$child - mu) ^ 2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
library(UsingR)
